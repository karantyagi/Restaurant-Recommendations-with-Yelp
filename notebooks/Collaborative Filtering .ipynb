{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the datasets\n",
    "reviews = pd.read_csv('reviews_restaurants_text.csv')\n",
    "reviews['text'] = reviews['text'].str[2:-2]\n",
    "\n",
    "#Undersampling of the dataset to get a balanced dataset\n",
    "review1 = reviews[reviews['stars'] == 1][0:12000]\n",
    "review2 = reviews[reviews['stars'] == 2][0:7000]\n",
    "review3 = reviews[reviews['stars'] == 3][0:12000]\n",
    "review4 = reviews[reviews['stars'] == 4][0:12000]\n",
    "review5 = reviews[reviews['stars'] == 5][0:12000]\n",
    "frames = [review1, review2, review3,review4,review5]\n",
    "reviews = pd.concat(frames)\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_users = reviews.user_id.unique().shape[0]\n",
    "unique_restaurants = reviews.business_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shraddha/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "train_data, test_data = cv.train_test_split(reviews, test_size=0.20)\n",
    "\n",
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((unique_users, unique_restaurants))\n",
    "# train_data_matrix\n",
    "for line in train_data.itertuples():\n",
    "#      print(line[5])\n",
    "     train_data_matrix[line[3], line[2]] = line[5]\n",
    "\n",
    "test_data_matrix = np.zeros((unique_users, unique_restaurants))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[3], line[2]] = line[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n",
    "\n",
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.382852990688319\n",
      "Item-based CF RMSE: 3.384852488490991\n",
      "User-based CF RMSE: 3.415862737871881\n",
      "Item-based CF RMSE: 3.416699872099379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print ('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))\n",
    "\n",
    "\n",
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
    "print ('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
